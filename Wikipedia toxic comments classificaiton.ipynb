{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'E:\\Simplilearn\\Cohort 3 - Jan\\PG DS - NLP _ Jul 25 - Aug 23 _ Shanti Swaroop (Cohort 3)\\Project\\Toxic Wiki')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from string import punctuation \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic'], dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4563\n",
       "1     437\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.toxic.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cleanup(data_raw, context_stop_words=['wiki', 'wikipedia', 'page', 'edit', 'article']):\n",
    "    \n",
    "    # lower\n",
    "    data_raw['comment_text'] = data_raw.comment_text.str.lower()\n",
    "    \n",
    "    #remove IP address\n",
    "    data_raw['comment_text'] = data_raw.comment_text.str.replace('((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.|$)){4}', '',)\n",
    "    \n",
    "    #remove string literals\n",
    "    data_raw['comment_text'] = data_raw.comment_text.str.replace(\"[\\n\\r\\t]\", '')\n",
    "    \n",
    "    #remove numbers\n",
    "    data_raw['comment_text'] = data_raw.comment_text.str.replace(\"\\d\", '')\n",
    "        \n",
    "    #remove email adress\n",
    "    data_raw['comment_text'] = data_raw.comment_text.str.replace('[a-zA-Z0-9-_.]+@[a-zA-Z0-9-_.]+', '')\n",
    "    \n",
    "    #remove punctaitions and special chracters\n",
    "    data_raw['comment_text'] = data_raw.comment_text.str.replace(\"[^\\w\\s]\",'')\n",
    "   \n",
    "        \n",
    "    #remove stop words\n",
    "    stop_words = list(punctuation) + stopwords.words('english') + context_stop_words\n",
    "    \n",
    "    clean_text=[]\n",
    "    for index in data_raw.index:\n",
    "        word_tokens = word_tokenize(data_raw['comment_text'][index])\n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "        clean_text.append(\" \".join(filtered_sentence[0:]))\n",
    "\n",
    "    data_raw['clean_text'] = clean_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=5000, step=1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_cleanup(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Data Term Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments = train_data.clean_text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words=[]\n",
    "for doc in all_comments:\n",
    "    words = word_tokenize(doc) \n",
    "    all_words.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('talk', 1060),\n",
       " ('please', 993),\n",
       " ('would', 962),\n",
       " ('one', 846),\n",
       " ('like', 832),\n",
       " ('dont', 792),\n",
       " ('ass', 708),\n",
       " ('also', 633),\n",
       " ('think', 628),\n",
       " ('fuck', 626),\n",
       " ('see', 619),\n",
       " ('know', 594),\n",
       " ('im', 546),\n",
       " ('use', 539),\n",
       " ('name', 531),\n",
       " ('people', 530),\n",
       " ('may', 530),\n",
       " ('articles', 527),\n",
       " ('time', 469),\n",
       " ('even', 400),\n",
       " ('make', 388),\n",
       " ('information', 383),\n",
       " ('deletion', 377),\n",
       " ('suck', 374),\n",
       " ('thanks', 372),\n",
       " ('good', 370),\n",
       " ('well', 369),\n",
       " ('could', 367),\n",
       " ('get', 365),\n",
       " ('want', 364),\n",
       " ('mexicans', 362),\n",
       " ('editing', 342),\n",
       " ('way', 336),\n",
       " ('edits', 331),\n",
       " ('help', 327),\n",
       " ('new', 325),\n",
       " ('first', 321),\n",
       " ('pages', 321),\n",
       " ('must', 316),\n",
       " ('sources', 316),\n",
       " ('user', 310),\n",
       " ('need', 308),\n",
       " ('say', 305),\n",
       " ('thank', 300),\n",
       " ('really', 299),\n",
       " ('many', 299),\n",
       " ('deleted', 296),\n",
       " ('source', 295),\n",
       " ('used', 282),\n",
       " ('image', 282)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.most_common(n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = train_data[['clean_text', 'toxic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_data[['clean_text']], final_data.toxic, random_state=123, test_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(max_features=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf = vect.fit_transform(X_train.clean_text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tf = vect.transform(X_test.clean_text.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclf = sv.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = svclf.predict(X_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Train Classifiction Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      3192\n",
      "           1       0.99      0.64      0.78       308\n",
      "\n",
      "    accuracy                           0.97      3500\n",
      "   macro avg       0.98      0.82      0.88      3500\n",
      "weighted avg       0.97      0.97      0.96      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\t\\t Train Classifiction Report:\\n\\n {classification_report(y_train, pred_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = svclf.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Test Classifiction Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1371\n",
      "           1       0.95      0.43      0.60       129\n",
      "\n",
      "    accuracy                           0.95      1500\n",
      "   macro avg       0.95      0.72      0.78      1500\n",
      "weighted avg       0.95      0.95      0.94      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\t\\t Test Classifiction Report:\\n\\n {classification_report(y_test, pred_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "svw = SVC(kernel='linear', class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "svwclf = sv.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_w = svwclf.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Test Classifiction Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1371\n",
      "           1       0.95      0.43      0.60       129\n",
      "\n",
      "    accuracy                           0.95      1500\n",
      "   macro avg       0.95      0.72      0.78      1500\n",
      "weighted avg       0.95      0.95      0.94      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\t\\t Test Classifiction Report:\\n\\n {classification_report(y_test, pred_test_w)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Param Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': [.01, .1, 1, 10, 100], 'kernel': ['rbf', 'linear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsv = GridSearchCV(svw, params, cv=kfold, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight='balanced', coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='linear', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
       "                         'kernel': ['rbf', 'linear']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='recall', verbose=0)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsv.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsv_pred_test = gsv.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Test Classifiction Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1371\n",
      "           1       0.37      0.62      0.46       129\n",
      "\n",
      "    accuracy                           0.87      1500\n",
      "   macro avg       0.66      0.76      0.69      1500\n",
      "weighted avg       0.91      0.87      0.89      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\t\\t Test Classifiction Report:\\n\\n {classification_report(y_test, gsv_pred_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['predicted'] = gsv_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_toxic = X_test[X_test.predicted == 1]['clean_text'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for sent in pred_toxic:\n",
    "    wt = word_tokenize(sent) \n",
    "    tokens.extend(wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('assfuck', 277),\n",
       " ('nigger', 185),\n",
       " ('fuck', 24),\n",
       " ('like', 17),\n",
       " ('right', 15),\n",
       " ('dont', 15),\n",
       " ('im', 13),\n",
       " ('go', 12),\n",
       " ('fucking', 11),\n",
       " ('life', 11),\n",
       " ('stop', 11),\n",
       " ('think', 10),\n",
       " ('ass', 10),\n",
       " ('would', 10),\n",
       " ('live', 10),\n",
       " ('really', 9),\n",
       " ('gay', 9),\n",
       " ('wing', 9),\n",
       " ('talk', 9),\n",
       " ('one', 8),\n",
       " ('people', 8),\n",
       " ('take', 8),\n",
       " ('hey', 8),\n",
       " ('get', 8),\n",
       " ('hell', 8),\n",
       " ('hate', 8),\n",
       " ('youre', 7),\n",
       " ('saturday', 7),\n",
       " ('night', 7),\n",
       " ('show', 7),\n",
       " ('truth', 6),\n",
       " ('sure', 6),\n",
       " ('even', 6),\n",
       " ('know', 6),\n",
       " ('going', 6),\n",
       " ('ive', 6),\n",
       " ('sketches', 6),\n",
       " ('award', 6),\n",
       " ('ill', 6),\n",
       " ('way', 6),\n",
       " ('little', 6),\n",
       " ('paul', 6),\n",
       " ('tibbit', 6),\n",
       " ('dead', 5),\n",
       " ('stupid', 5),\n",
       " ('man', 5),\n",
       " ('asshole', 5),\n",
       " ('rather', 5),\n",
       " ('guy', 5),\n",
       " ('someone', 5)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.most_common(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
